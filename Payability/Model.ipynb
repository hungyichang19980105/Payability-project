{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "import lightgbm as lgbm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, recall_score, confusion_matrix, precision_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dataset\n",
    "df = pd.read_csv('data/input.csv')\n",
    "df2 = df[['transaction_risk_score','cc_amount','ledger_balance','cardholder_presence','card_presence',\n",
    "          'partial_approval_capable','channel','processing_type','date','cc_acceptor_state','cc_acceptor_country','is_fraud']]\n",
    "df2 = df2.sort_values(by='date')\n",
    "df2 = df2.drop(\"date\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df2.drop(\"is_fraud\",axis=1)\n",
    "y = df2[['is_fraud']].values.flatten()\n",
    "scalar = StandardScaler()\n",
    "X_scale = scalar.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "training_set, test_set = np.split(df2, [int(.8 *len(df2))])\n",
    "\n",
    "X_train = training_set.drop(\"is_fraud\",axis=1)\n",
    "y_train = training_set[['is_fraud']].values.flatten()\n",
    "\n",
    "X_test = test_set.drop(\"is_fraud\",axis=1)\n",
    "y_test = test_set[['is_fraud']].values.flatten()\n",
    "\n",
    "scalar = StandardScaler()\n",
    "x_train_scale = scalar.fit_transform(X_train)\n",
    "x_test_scale = scalar.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of train set:  (35707, 10)\n",
      "Size of each fold:  3570\n",
      "\n",
      "Splitting the first 2 chunks with ratio 1:1\n",
      "Size of train + test:  (7140, 10)\n",
      "Precision on fold 2:  0.972\n",
      "Recall on fold 2:  0.86\n",
      "Accuracy on fold 2:  0.991\n",
      "f1_score on fold 2:  0.912\n",
      "\n",
      "Splitting the first 3 chunks with ratio 2:1\n",
      "Size of train + test:  (10710, 10)\n",
      "Precision on fold 3:  0.985\n",
      "Recall on fold 3:  0.84\n",
      "Accuracy on fold 3:  0.989\n",
      "f1_score on fold 3:  0.907\n",
      "\n",
      "Splitting the first 4 chunks with ratio 3:1\n",
      "Size of train + test:  (14280, 10)\n",
      "Precision on fold 4:  0.977\n",
      "Recall on fold 4:  0.809\n",
      "Accuracy on fold 4:  0.991\n",
      "f1_score on fold 4:  0.885\n",
      "\n",
      "Splitting the first 5 chunks with ratio 4:1\n",
      "Size of train + test:  (17850, 10)\n",
      "Precision on fold 5:  0.97\n",
      "Recall on fold 5:  0.757\n",
      "Accuracy on fold 5:  0.987\n",
      "f1_score on fold 5:  0.85\n",
      "\n",
      "Splitting the first 6 chunks with ratio 5:1\n",
      "Size of train + test:  (21420, 10)\n",
      "Precision on fold 6:  0.948\n",
      "Recall on fold 6:  0.92\n",
      "Accuracy on fold 6:  0.996\n",
      "f1_score on fold 6:  0.934\n",
      "\n",
      "Splitting the first 7 chunks with ratio 6:1\n",
      "Size of train + test:  (24990, 10)\n",
      "Precision on fold 7:  0.994\n",
      "Recall on fold 7:  0.898\n",
      "Accuracy on fold 7:  0.994\n",
      "f1_score on fold 7:  0.944\n",
      "\n",
      "Splitting the first 8 chunks with ratio 7:1\n",
      "Size of train + test:  (28560, 10)\n",
      "Precision on fold 8:  0.987\n",
      "Recall on fold 8:  1.0\n",
      "Accuracy on fold 8:  0.999\n",
      "f1_score on fold 8:  0.993\n",
      "\n",
      "Splitting the first 9 chunks with ratio 8:1\n",
      "Size of train + test:  (32130, 10)\n",
      "Precision on fold 9:  0.991\n",
      "Recall on fold 9:  1.0\n",
      "Accuracy on fold 9:  1.0\n",
      "f1_score on fold 9:  0.996\n",
      "\n",
      "Splitting the first 10 chunks with ratio 9:1\n",
      "Size of train + test:  (35700, 10)\n",
      "Precision on fold 10:  0.986\n",
      "Recall on fold 10:  1.0\n",
      "Accuracy on fold 10:  0.999\n",
      "f1_score on fold 10:  0.993\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9788888888888889, 0.8982222222222221, 0.994, 0.9348888888888889]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ÔºÉTime Series split\n",
    "def TimeSeriesKFold(X_train, y_train, number_folds, method):\n",
    "    print('Size of train set: ', X_train.shape)\n",
    "    k = int(np.floor(float(X_train.shape[0]) / number_folds))\n",
    "    print('Size of each fold: ', k)\n",
    "    accuracies = np.zeros(number_folds-1)\n",
    "    recalls = np.zeros(number_folds-1)\n",
    "    precisions = np.zeros(number_folds-1)\n",
    "    f1_scores = np.zeros(number_folds-1)\n",
    "    for i in range(2, number_folds + 1):\n",
    "        print()\n",
    "        split = float(i-1)/i\n",
    "        print('Splitting the first ' + str(i) + ' chunks with ratio ' + str(i-1) + ':1')\n",
    "        X = X_train[:(k*i)]\n",
    "        y = y_train[:(k*i)]\n",
    "        print('Size of train + test: ', X.shape)\n",
    "        index = int(np.floor(X.shape[0] * split))\n",
    "        X_trainFolds = X[:index]        \n",
    "        y_trainFolds = y[:index]\n",
    "        \n",
    "        # fold used to test the model\n",
    "        X_testFold = X[(index + 1):]\n",
    "        y_testFold = y[(index + 1):]\n",
    "        \n",
    "        if method == \"RandomForest\":\n",
    "            clf = RandomForestClassifier(n_estimators=500, max_depth=15, random_state=0)  \n",
    "        elif method == \"LightGBM\":\n",
    "            clf = lgbm.LGBMClassifier(objective=\"binary\", n_estimators=10000)\n",
    "            \n",
    "        clf.fit(X_trainFolds,y_trainFolds)\n",
    "        pred = clf.predict(X_testFold)\n",
    "        precisions[i-2] = round(precision_score(y_testFold, pred),3)\n",
    "        recalls[i-2] = round(recall_score(y_testFold, pred),3)\n",
    "        accuracies[i-2] = round(accuracy_score(y_testFold, pred),3)\n",
    "        f1_scores[i-2] = round(f1_score(y_testFold, pred),3)\n",
    "        \n",
    "        print('Precision on fold ' + str(i) + ': ', precisions[i-2])\n",
    "        print('Recall on fold ' + str(i) + ': ', recalls[i-2])\n",
    "        print('Accuracy on fold ' + str(i) + ': ', accuracies[i-2])\n",
    "        print('f1_score on fold ' + str(i) + ': ', f1_scores[i-2])\n",
    "    return [precisions.mean(),recalls.mean(),accuracies.mean(),f1_scores.mean()]\n",
    "\n",
    "TimeSeriesKFold(X_scale, y, 10, 'LightGBM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[17012,     7],\n",
       "       [   22,   813]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
