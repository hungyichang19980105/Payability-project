{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: import-ipynb in /opt/anaconda3/lib/python3.8/site-packages (0.1.3)\n",
      "\u001b[33mWARNING: You are using pip version 21.0.1; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the '/opt/anaconda3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install import-ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import import_ipynb\n",
    "import Model\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "import lightgbm as lgbm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, recall_score, confusion_matrix, precision_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dataset\n",
    "df = pd.read_csv('data/input.csv')\n",
    "df2 = df[['transaction_risk_score','cc_amount','ledger_balance','cardholder_presence','card_presence',\n",
    "          'partial_approval_capable','channel','processing_type','date','cc_acceptor_state','cc_acceptor_country','is_fraud']]\n",
    "df2 = df2.sort_values(by='date')\n",
    "df2 = df2.drop(\"date\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----RandomForest-----\n",
      "Size of train set:  (28565, 10)\n",
      "Size of test set:  (7142, 10)\n",
      "\n",
      "Confusion-matrix: \n",
      "[[6741    1]\n",
      " [   0  400]]\n",
      "\n",
      "Classification-report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      6742\n",
      "           1       1.00      1.00      1.00       400\n",
      "\n",
      "    accuracy                           1.00      7142\n",
      "   macro avg       1.00      1.00      1.00      7142\n",
      "weighted avg       1.00      1.00      1.00      7142\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Model.GeneralSplit(df2,.8,'RandomForest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----LightGBM-----\n",
      "Size of train set:  (28565, 10)\n",
      "Size of test set:  (7142, 10)\n",
      "\n",
      "Confusion-matrix: \n",
      "[[6736    6]\n",
      " [   0  400]]\n",
      "\n",
      "Classification-report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      6742\n",
      "           1       0.99      1.00      0.99       400\n",
      "\n",
      "    accuracy                           1.00      7142\n",
      "   macro avg       0.99      1.00      1.00      7142\n",
      "weighted avg       1.00      1.00      1.00      7142\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Model.GeneralSplit(df2,.8,'LightGBM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df2.drop(\"is_fraud\",axis=1)\n",
    "y = df2[['is_fraud']].values.flatten()\n",
    "scalar = StandardScaler()\n",
    "X_scale = scalar.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----RandomForest-----\n",
      "Size of data set:  (35707, 10)\n",
      "Size of each fold:  3570\n",
      "\n",
      "Splitting the first 2 chunks with ratio 1:1\n",
      "Size of train + test:  (7140, 10)\n",
      "Precision on fold 2:  0.971\n",
      "Recall on fold 2:  0.85\n",
      "Accuracy on fold 2:  0.99\n",
      "F1_score on fold 2:  0.907\n",
      "Confusion-matrix: \n",
      "[[3364    5]\n",
      " [  30  170]]\n",
      "\n",
      "Splitting the first 3 chunks with ratio 2:1\n",
      "Size of train + test:  (10710, 10)\n",
      "Precision on fold 3:  1.0\n",
      "Recall on fold 3:  0.835\n",
      "Accuracy on fold 3:  0.989\n",
      "F1_score on fold 3:  0.91\n",
      "Confusion-matrix: \n",
      "[[3338    0]\n",
      " [  38  193]]\n",
      "\n",
      "Splitting the first 4 chunks with ratio 3:1\n",
      "Size of train + test:  (14280, 10)\n",
      "Precision on fold 4:  0.984\n",
      "Recall on fold 4:  0.79\n",
      "Accuracy on fold 4:  0.99\n",
      "F1_score on fold 4:  0.876\n",
      "Confusion-matrix: \n",
      "[[3410    2]\n",
      " [  33  124]]\n",
      "\n",
      "Splitting the first 5 chunks with ratio 4:1\n",
      "Size of train + test:  (17850, 10)\n",
      "Precision on fold 5:  0.992\n",
      "Recall on fold 5:  0.746\n",
      "Accuracy on fold 5:  0.988\n",
      "F1_score on fold 5:  0.851\n",
      "Confusion-matrix: \n",
      "[[3399    1]\n",
      " [  43  126]]\n",
      "\n",
      "Splitting the first 6 chunks with ratio 5:1\n",
      "Size of train + test:  (21420, 10)\n",
      "Precision on fold 6:  0.96\n",
      "Recall on fold 6:  0.95\n",
      "Accuracy on fold 6:  0.997\n",
      "F1_score on fold 6:  0.955\n",
      "Confusion-matrix: \n",
      "[[3465    4]\n",
      " [   5   95]]\n",
      "\n",
      "Splitting the first 7 chunks with ratio 6:1\n",
      "Size of train + test:  (24990, 10)\n",
      "Precision on fold 7:  0.994\n",
      "Recall on fold 7:  0.893\n",
      "Accuracy on fold 7:  0.994\n",
      "F1_score on fold 7:  0.941\n",
      "Confusion-matrix: \n",
      "[[3381    1]\n",
      " [  20  167]]\n",
      "\n",
      "Splitting the first 8 chunks with ratio 7:1\n",
      "Size of train + test:  (28560, 10)\n",
      "Precision on fold 8:  1.0\n",
      "Recall on fold 8:  1.0\n",
      "Accuracy on fold 8:  1.0\n",
      "F1_score on fold 8:  1.0\n",
      "Confusion-matrix: \n",
      "[[3421    0]\n",
      " [   0  148]]\n",
      "\n",
      "Splitting the first 9 chunks with ratio 8:1\n",
      "Size of train + test:  (32130, 10)\n",
      "Precision on fold 9:  1.0\n",
      "Recall on fold 9:  1.0\n",
      "Accuracy on fold 9:  1.0\n",
      "F1_score on fold 9:  1.0\n",
      "Confusion-matrix: \n",
      "[[3453    0]\n",
      " [   0  116]]\n",
      "\n",
      "Splitting the first 10 chunks with ratio 9:1\n",
      "Size of train + test:  (35700, 10)\n",
      "Precision on fold 10:  0.996\n",
      "Recall on fold 10:  1.0\n",
      "Accuracy on fold 10:  1.0\n",
      "F1_score on fold 10:  0.998\n",
      "Confusion-matrix: \n",
      "[[3284    1]\n",
      " [   0  284]]\n",
      "Precision mean: 0.9885555555555556\n",
      "Recall mean: 0.896\n",
      "Accuracy mean: 0.9942222222222222\n",
      "F1-Score mean: 0.9375555555555555\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([0.971, 1.   , 0.984, 0.992, 0.96 , 0.994, 1.   , 1.   , 0.996]),\n",
       " array([0.85 , 0.835, 0.79 , 0.746, 0.95 , 0.893, 1.   , 1.   , 1.   ]),\n",
       " array([0.99 , 0.989, 0.99 , 0.988, 0.997, 0.994, 1.   , 1.   , 1.   ]),\n",
       " array([0.907, 0.91 , 0.876, 0.851, 0.955, 0.941, 1.   , 1.   , 0.998])]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Model.TimeSeriesKFold(X, y, 10, 'RandomForest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----LightGBM-----\n",
      "Size of data set:  (35707, 10)\n",
      "Size of each fold:  3570\n",
      "\n",
      "Splitting the first 2 chunks with ratio 1:1\n",
      "Size of train + test:  (7140, 10)\n",
      "Precision on fold 2:  0.961\n",
      "Recall on fold 2:  0.87\n",
      "Accuracy on fold 2:  0.991\n",
      "F1_score on fold 2:  0.913\n",
      "Confusion-matrix: \n",
      "[[3362    7]\n",
      " [  26  174]]\n",
      "\n",
      "Splitting the first 3 chunks with ratio 2:1\n",
      "Size of train + test:  (10710, 10)\n",
      "Precision on fold 3:  0.985\n",
      "Recall on fold 3:  0.84\n",
      "Accuracy on fold 3:  0.989\n",
      "F1_score on fold 3:  0.907\n",
      "Confusion-matrix: \n",
      "[[3335    3]\n",
      " [  37  194]]\n",
      "\n",
      "Splitting the first 4 chunks with ratio 3:1\n",
      "Size of train + test:  (14280, 10)\n",
      "Precision on fold 4:  0.984\n",
      "Recall on fold 4:  0.803\n",
      "Accuracy on fold 4:  0.991\n",
      "F1_score on fold 4:  0.884\n",
      "Confusion-matrix: \n",
      "[[3410    2]\n",
      " [  31  126]]\n",
      "\n",
      "Splitting the first 5 chunks with ratio 4:1\n",
      "Size of train + test:  (17850, 10)\n",
      "Precision on fold 5:  0.969\n",
      "Recall on fold 5:  0.74\n",
      "Accuracy on fold 5:  0.987\n",
      "F1_score on fold 5:  0.839\n",
      "Confusion-matrix: \n",
      "[[3396    4]\n",
      " [  44  125]]\n",
      "\n",
      "Splitting the first 6 chunks with ratio 5:1\n",
      "Size of train + test:  (21420, 10)\n",
      "Precision on fold 6:  0.907\n",
      "Recall on fold 6:  0.49\n",
      "Accuracy on fold 6:  0.984\n",
      "F1_score on fold 6:  0.636\n",
      "Confusion-matrix: \n",
      "[[3464    5]\n",
      " [  51   49]]\n",
      "\n",
      "Splitting the first 7 chunks with ratio 6:1\n",
      "Size of train + test:  (24990, 10)\n",
      "Precision on fold 7:  0.994\n",
      "Recall on fold 7:  0.866\n",
      "Accuracy on fold 7:  0.993\n",
      "F1_score on fold 7:  0.926\n",
      "Confusion-matrix: \n",
      "[[3381    1]\n",
      " [  25  162]]\n",
      "\n",
      "Splitting the first 8 chunks with ratio 7:1\n",
      "Size of train + test:  (28560, 10)\n",
      "Precision on fold 8:  0.993\n",
      "Recall on fold 8:  1.0\n",
      "Accuracy on fold 8:  1.0\n",
      "F1_score on fold 8:  0.997\n",
      "Confusion-matrix: \n",
      "[[3420    1]\n",
      " [   0  148]]\n",
      "\n",
      "Splitting the first 9 chunks with ratio 8:1\n",
      "Size of train + test:  (32130, 10)\n",
      "Precision on fold 9:  0.991\n",
      "Recall on fold 9:  1.0\n",
      "Accuracy on fold 9:  1.0\n",
      "F1_score on fold 9:  0.996\n",
      "Confusion-matrix: \n",
      "[[3452    1]\n",
      " [   0  116]]\n",
      "\n",
      "Splitting the first 10 chunks with ratio 9:1\n",
      "Size of train + test:  (35700, 10)\n",
      "Precision on fold 10:  0.99\n",
      "Recall on fold 10:  1.0\n",
      "Accuracy on fold 10:  0.999\n",
      "F1_score on fold 10:  0.995\n",
      "Confusion-matrix: \n",
      "[[3282    3]\n",
      " [   0  284]]\n",
      "Precision mean: 0.9748888888888888\n",
      "Recall mean: 0.8454444444444444\n",
      "Accuracy mean: 0.9926666666666668\n",
      "F1-Score mean: 0.8992222222222223\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([0.961, 0.985, 0.984, 0.969, 0.907, 0.994, 0.993, 0.991, 0.99 ]),\n",
       " array([0.87 , 0.84 , 0.803, 0.74 , 0.49 , 0.866, 1.   , 1.   , 1.   ]),\n",
       " array([0.991, 0.989, 0.991, 0.987, 0.984, 0.993, 1.   , 1.   , 0.999]),\n",
       " array([0.913, 0.907, 0.884, 0.839, 0.636, 0.926, 0.997, 0.996, 0.995])]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Model.TimeSeriesKFold(X, y, 10, 'LightGBM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
